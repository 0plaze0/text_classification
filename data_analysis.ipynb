{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sports vs Politics Text Classification - Exploratory Data Analysis\n",
        "\n",
        "This notebook contains the data analysis and visualization components of the project.\n",
        "For the classification models, see `text_classifier.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"sunilthite/text-document-classification-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "files = os.listdir(path)\n",
        "print(\"Files in dataset:\", files)\n",
        "\n",
        "# Load the CSV file\n",
        "csv_path = os.path.join(path, 'df_file.csv')\n",
        "print(f\"Using CSV at: {csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv(csv_path)\n",
        "display(df.head())\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep only Politics and Sports\n",
        "label_map = {0: \"Politics\", 1: \"Sports\"}\n",
        "\n",
        "df = df[df[\"Label\"].isin([0, 1])]\n",
        "df[\"Label\"] = df[\"Label\"].map(label_map)\n",
        "\n",
        "print(\"Class distribution:\")\n",
        "print(df[\"Label\"].value_counts())\n",
        "print(f\"\\nTotal documents: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic cleaning\n",
        "df.dropna(subset=[\"Text\"], inplace=True)\n",
        "df[\"Text\"] = df[\"Text\"].astype(str)\n",
        "df = df[df[\"Text\"].str.strip() != \"\"]\n",
        "\n",
        "print(f\"After cleaning: {len(df)} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text preprocessing function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df[\"clean_text\"] = df[\"Text\"].apply(clean_text)\n",
        "print(\"Text preprocessing completed!\")\n",
        "\n",
        "# Show example\n",
        "print(\"\\nExample:\")\n",
        "print(f\"Original: {df.iloc[0]['Text'][:100]}...\")\n",
        "print(f\"Cleaned: {df.iloc[0]['clean_text'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Engineering\n",
        "df[\"word_count\"] = df[\"clean_text\"].apply(lambda x: len(x.split()))\n",
        "df[\"char_count\"] = df[\"clean_text\"].apply(len)\n",
        "\n",
        "print(\"Feature statistics:\")\n",
        "print(df[[\"word_count\", \"char_count\"]].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "df[\"Label\"].value_counts().plot(kind=\"bar\", color=['#3498db', '#e74c3c'])\n",
        "plt.title(\"Document Count: Politics vs Sports\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Class\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Text Length Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Word count distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(df[\"word_count\"], bins=40, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "plt.xlabel(\"Word Count\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.title(\"Word Count Distribution\", fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Word count by class\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x=\"Label\", y=\"word_count\", data=df, palette=['#3498db', '#e74c3c'])\n",
        "plt.title(\"Word Count by Class\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Class\", fontsize=12)\n",
        "plt.ylabel(\"Word Count\", fontsize=12)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 N-gram Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top unigrams function\n",
        "def top_ngrams(texts, ngram_range=(1,1), top_n=20):\n",
        "    vec = CountVectorizer(\n",
        "        stop_words=\"english\",\n",
        "        ngram_range=ngram_range\n",
        "    )\n",
        "    X = vec.fit_transform(texts)\n",
        "    freqs = X.sum(axis=0)\n",
        "\n",
        "    words = [\n",
        "        (w, freqs[0, i])\n",
        "        for w, i in vec.vocabulary_.items()\n",
        "    ]\n",
        "\n",
        "    return sorted(words, key=lambda x: x[1], reverse=True)[:top_n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top unigrams visualization\n",
        "uni = top_ngrams(df[\"clean_text\"], (1,1))\n",
        "words, counts = zip(*uni)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(words, counts, color='steelblue', edgecolor='black')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Words\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.title(\"Top 20 Unigrams (Politics + Sports)\", fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Word Cloud Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall word cloud\n",
        "text_all = \" \".join(df[\"clean_text\"].values)\n",
        "\n",
        "wc_all = WordCloud(\n",
        "    width=1200,\n",
        "    height=600,\n",
        "    background_color=\"white\",\n",
        "    stopwords=STOPWORDS,\n",
        "    max_words=200,\n",
        "    colormap='viridis'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.imshow(wc_all.generate(text_all), interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Word Cloud \u2013 Politics & Sports Combined\", fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class-specific word clouds\n",
        "politics_text = \" \".join(\n",
        "    df[df[\"Label\"] == \"Politics\"][\"clean_text\"].values\n",
        ")\n",
        "\n",
        "sports_text = \" \".join(\n",
        "    df[df[\"Label\"] == \"Sports\"][\"clean_text\"].values\n",
        ")\n",
        "\n",
        "wc = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color=\"white\",\n",
        "    stopwords=STOPWORDS,\n",
        "    max_words=200\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# Politics\n",
        "axes[0].imshow(wc.generate(politics_text), interpolation=\"bilinear\")\n",
        "axes[0].set_title(\"Politics\", fontsize=14, fontweight='bold')\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Sports\n",
        "wc_sports = WordCloud(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color=\"white\",\n",
        "    stopwords=STOPWORDS,\n",
        "    max_words=200,\n",
        "    colormap='Reds'\n",
        ")\n",
        "axes[1].imshow(wc_sports.generate(sports_text), interpolation=\"bilinear\")\n",
        "axes[1].set_title(\"Sports\", fontsize=14, fontweight='bold')\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Word Clouds by Category\", fontsize=16, fontweight='bold', y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary\n",
        "\n",
        "This notebook contains all the exploratory data analysis and visualizations.\n",
        "\n",
        "**For classification models and predictions, run:**\n",
        "```bash\n",
        "python text_classifier.py\n",
        "```\n",
        "\n",
        "The classifier script will:\n",
        "- Train Naive Bayes, Random Forest, and SVM models\n",
        "- Generate performance metrics\n",
        "- Create confusion matrices and comparison plots"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}